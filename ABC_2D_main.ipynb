{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "Use kernel \"ABM_env\" -- see README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import cProfile\n",
    "import pickle\n",
    "import scipy as sci\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "from ABC_2D_case_class import *\n",
    "from ABC_2D_data_set_class import * \n",
    "%run ABC_2D_data_set_class.py\n",
    "%run ABC_2D_case_class.py\n",
    "%run ABC_2D_weight_functions.py\n",
    "\n",
    "case_set_allow_save=0 # Protection from accidental saving"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the case set\n",
    "\n",
    "# Load in sample/test data to try to calibrate to\n",
    "data_file='./Data/Test Data/Two-parameter case/new_I_data_Two-Pop-NEW-COMBINED-TEST.pickle'\n",
    "params_file='./Data/Test Data/Two-parameter case/variable_parameter_values_Two-Pop-NEW-COMBINED-TEST.csv'\n",
    "sample_data=data_set(data_file=data_file,params_file=params_file,T=300,mob_range=[0.005,0.025],jp_range=[0.,0.001])\n",
    "\n",
    "\n",
    "# Load in a portion of training data (full training data set is very large)\n",
    "data_file='./Data/Training Data/Two-parameter case/Calibration method 2/new_I_data_Two-Pop-Cont.pickle'\n",
    "params_file='./Data/Training Data/Two-parameter case/Calibration method 2/variable_parameter_values_Two-Pop-Cont.csv'\n",
    "\n",
    "segment_start = 0\n",
    "segment_end = 10000\n",
    "training_data=data_set(data_file=data_file,params_file=params_file,T=300,mob_range=[0.005,0.025],jp_range=[0.,0.001], limit_data_range = True, data_range_start = segment_start, data_range_end = segment_end)\n",
    "\n",
    "#Initialize case set with sample and training data\n",
    "cases=case_set(sample_data,training_data)\n",
    "cases.initialize_all_cases(mod=100) #only initialize every 100th case from sample/test data to calibrate on, set mod=1 to intialize every test data set\n",
    "\n",
    "#Run scoring (calculate ABC \"distances\" between test data and training data)\n",
    "cases.run_scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_num = 5 #choose test dataset to run calibration on\n",
    "cases.case_list[case_num].make_single_analysis(epanechnikov,0.02,0.2,res=200)\n",
    "# cases.run_single_analysis(step,0.02,0.2,res=200) # run analysis on all cases\n",
    "cases.case_list[case_num].analysis_single.make_kde_plot_2D(plot_matches=True) # produce plot of inferred posterior (opacity of plotted matches corresponds to weight)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction usage\n",
    "The code below reproduces the calibration and simulation-based calibration tests run for the two-parameter case using calibration method 2. Full analysis may be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sample data sets\n",
    "\n",
    "#Full sample/test data set with 1666 sets:\n",
    "data_file='./Data/Test Data/Two-parameter case/new_I_data_Two-Pop-NEW-COMBINED-TEST.pickle'\n",
    "params_file='./Data/Test Data/Two-parameter case/variable_parameter_values_Two-Pop-NEW-COMBINED-TEST.csv'\n",
    "sample_data=data_set(data_file=data_file,params_file=params_file,T=300,mob_range=[0.005,0.025],jp_range=[0.,0.001])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training data sets -- run accumulation of infections over time\n",
    "##This doesn't need to be rerun if already have training_data_I_ABM_ALL.pickle file, can go to next cell.\n",
    "\n",
    "#Training data with 85000 sets:\n",
    "data_file='./Data/Training Data/Two-parameter case/Calibration method 2/new_I_data_Two-Pop-Cont.pickle'\n",
    "params_file='./Data/Training Data/Two-parameter case/Calibration method 2/variable_parameter_values_Two-Pop-Cont.csv'\n",
    "training_data=data_set(data_file=data_file,params_file=params_file,T=300,mob_range=[0.005,0.025],jp_range=[0.,0.001], limit_data_range = False)\n",
    "filename = './Data/Training Data/Two-parameter case/Calibration method 2/training_data_I_ABM_ALL.pickle' \n",
    "with open(filename, 'wb') as handle:\n",
    "    pickle.dump(training_data.I_ABM_ALL, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "\n",
    "#Raw training data files:\n",
    "data_file='./Data/Training Data/Two-parameter case/Calibration method 2/new_I_data_Two-Pop-Cont.pickle'\n",
    "params_file='./Data/Training Data/Two-parameter case/Calibration method 2/variable_parameter_values_Two-Pop-Cont.csv'\n",
    "\n",
    "#Accumulated training data file:\n",
    "filename = './Data/Training Data/Two-parameter case/Calibration method 2/training_data_I_ABM_ALL.pickle' \n",
    "\n",
    "with open(filename, 'rb') as handle:\n",
    "    loaded_variable = pickle.load(handle)\n",
    "\n",
    "I_ABM_ALL = loaded_variable.astype(np.int8)\n",
    "\n",
    "#Put training data data set together:\n",
    "training_data = data_set(data_file=data_file,params_file=params_file,T=300,mob_range=[0.005,0.025],jp_range=[0.,0.001], limit_data_range = False, accumulated_data = True, I_ABM_ALL = I_ABM_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run scoring (calculating scores between test data sets and each training data set):\n",
    "\n",
    "#Create case set:\n",
    "cases=case_set(sample_data,training_data)\n",
    "cases.initialize_all_cases(mod=1)\n",
    "cases.run_scoring(style = \"concat\")\n",
    "\n",
    "#Save case set:\n",
    "case_set_allow_save = 1\n",
    "\n",
    "if case_set_allow_save==1: #So that I don't overwrite the data with zeros\n",
    "    print('Saving...')\n",
    "    with open('./Data/Training Data/Two-parameter case/Calibration method 2/case_set.pickle', 'wb') as handle:\n",
    "        pickle.dump(cases, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('Done')\n",
    "    \n",
    "case_set_allow_save = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do analysis, saving results along the way\n",
    "\n",
    "segments = np.arange(0,1700,50) #do analysis in segments of 50 samples at a time (saving results in between)\n",
    "segments[-1] = 1666\n",
    "print(segments.shape)\n",
    "\n",
    "for i in range(0, segments.shape[0]):\n",
    "\n",
    "    #LOAD IN CASE SET (WITH PRE-CALCULATED SCORES) IF NOT ALREADY LOADED\n",
    "    with open('./Data/Training Data/Two-parameter case/Calibration method 2/case_set.pickle', 'rb') as handle:\n",
    "        cases = pickle.load(handle)\n",
    "\n",
    "    print('Starting analysis on segment ', i, '\\n')\n",
    "\n",
    "    #Specify ABC hyperparameters to run:\n",
    "    \n",
    "    # weight_function_vect=[step, neg_exp, linear, epanechnikov] # i\n",
    "    # centriod_vect=[0.002,0.02,0.2,2,20] # j\n",
    "    # estimator_bw_vect=[0.1,0.3,1,3,10] # k\n",
    "    weight_function_vect=[epanechnikov] # i <-- to run only one option, still input option in a list []\n",
    "    centriod_vect=[0.002] # j\n",
    "    estimator_bw_vect=[0.1] # k\n",
    "    res=500\n",
    "\n",
    "    # Anaysis for some of the cases in the set:\n",
    "    start_time = time.time()\n",
    "    cases.run_partial_analysis_array(weight_function_vect,centriod_vect,estimator_bw_vect,start = segments[i], end = segments[i+1], res=res)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed Run Time: {elapsed_time} seconds\")\n",
    "\n",
    "    #Save data:\n",
    "    variables_to_save = ['KDE', 'KDE_mob', 'KDE_jp', 'mean_mob', 'mean_jp', 'continous_rank_mob',\n",
    "                         'continous_rank_jp', 'crps_mob', 'crps_jp', 'weights', 'inside_95',\n",
    "                         'inside_50', 'inside_hollow_95', 'inside_hollow_50', 'mob_grid', 'jp_grid']\n",
    "\n",
    "    for variable_name in variables_to_save:\n",
    "        \n",
    "        variable_data = cases.get_attribute_from_partial_case_list_analysis_array(variable_name, start = segments[i], end = segments[i+1])\n",
    "        filename = f'./Data/ABC_2D_results/{variable_name}_{i}.pickle'\n",
    "        \n",
    "        with open(filename, 'wb') as handle:\n",
    "            pickle.dump(variable_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print(f'Saved {variable_name} to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in ABC results\n",
    "\n",
    "variables_to_load = ['continous_rank_mob', 'continous_rank_jp', 'crps_mob', 'crps_jp', 'KDE_mob', 'KDE_jp',\n",
    "                    'mob_grid', 'jp_grid', 'KDE', 'inside_95',\n",
    "                    'inside_50', 'inside_hollow_95', 'inside_hollow_50']\n",
    "\n",
    "loaded_data = {}\n",
    "\n",
    "for i in range(33):\n",
    "    for variable_name in variables_to_load:\n",
    "        try:\n",
    "            filename = f'./Data/ABC_2D_results/{variable_name}_{i}.pickle'\n",
    "\n",
    "            print(i)\n",
    "            with open(filename, 'rb') as handle:\n",
    "                loaded_variable = pickle.load(handle)\n",
    "            if i == 0:\n",
    "                loaded_data[variable_name] = loaded_variable\n",
    "            else:\n",
    "                loaded_data[variable_name] = loaded_data[variable_name]+loaded_variable\n",
    "                \n",
    "            # print(f'Loaded {variable_name} from {filename}')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting SBC results\n",
    "Reproduces two-parameter case results in Fig. 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting SBC results\n",
    "\n",
    "# ---------------------- Mobility: ------------------------\n",
    "\n",
    "continuous_rank = np.array(loaded_data['continous_rank_mob'])[:,0,0,0]\n",
    "\n",
    "rank_test=[]\n",
    "for i in range(0,1666):\n",
    "    rank_test.append(continuous_rank[i])\n",
    "\n",
    "# plt.plot(np.sort(rank_test))\n",
    "# plt.xlabel('Index sorted by quantile')\n",
    "# plt.ylabel('Quantile')\n",
    "# plt.plot([0,len(rank_test)],[0,1])\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(np.array(range(len(rank_test))),rank_test)\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel('Quantile')\n",
    "# plt.show()\n",
    "\n",
    "vals = rank_test\n",
    "n_bins = 51\n",
    "counts, bins = np.histogram(vals, bins=n_bins, range=None, density=None, weights=None)\n",
    "plt.figure(dpi = 500, figsize = (3.5,1.75))\n",
    "plt.stairs(counts, bins, fill = True)\n",
    "plt.xlabel('Mobility quantile')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.savefig('figs_final/mob_ABC_SBC_histogram_2d.png',bbox_inches='tight')\n",
    "plt.savefig('mob_ABC_SBC_histogram_2d.png',bbox_inches='tight')\n",
    "print('p-value:', sci.stats.chisquare(counts).pvalue)\n",
    "plt.show()\n",
    "\n",
    "# ------------------- Jumping probability: --------------------\n",
    "\n",
    "continuous_rank = np.array(loaded_data['continous_rank_jp'])[:,0,0,0]\n",
    "\n",
    "rank_test=[]\n",
    "for i in range(0,1666):\n",
    "    rank_test.append(continuous_rank[i])\n",
    "\n",
    "# plt.plot(np.sort(rank_test))\n",
    "# plt.xlabel('Index sorted by quantile')\n",
    "# plt.ylabel('Quantile')\n",
    "# plt.plot([0,len(rank_test)],[0,1])\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(np.array(range(len(rank_test))),rank_test)\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel('Quantile')\n",
    "# plt.show()\n",
    "\n",
    "vals = rank_test\n",
    "n_bins = 51\n",
    "counts, bins = np.histogram(vals, bins=n_bins, range=None, density=None, weights=None)\n",
    "plt.figure(dpi = 500, figsize = (3.5,1.75))\n",
    "plt.stairs(counts, bins, fill = True)\n",
    "plt.xlabel('Jumping probability quantile')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.savefig('figs_final/JP_ABC_SBC_histogram_2d.png',bbox_inches='tight')\n",
    "plt.savefig('JP_ABC_SBC_histogram_2d.png',bbox_inches='tight')\n",
    "print('p-value:', sci.stats.chisquare(counts).pvalue)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting KDE and marginals from loaded results data\n",
    "set: \"sample_id = 1627\" to recreate example in Fig. 12\n",
    " \n",
    "set: \"sample_id = 114\" to recreate example in Fig. 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 1627\n",
    "KDE = loaded_data['KDE'][sample_id][0,0,0,:,:]\n",
    "inside_95 = loaded_data['inside_95'][sample_id][0,0,0,:,:]\n",
    "inside_50 = loaded_data['inside_50'][sample_id][0,0,0,:,:]\n",
    "inside_hollow_95 = loaded_data['inside_hollow_95'][sample_id][0,0,0,:,:]\n",
    "inside_hollow_50 = loaded_data['inside_hollow_50'][sample_id][0,0,0,:,:]\n",
    "y_flat = loaded_data['jp_grid'][0][0,0,0,:,:]\n",
    "x_flat = loaded_data['mob_grid'][0][0,0,0,:,:]\n",
    "res = 500\n",
    "\n",
    "actual_mob = cases.sample_data.mobilities[sample_id]\n",
    "actual_jp = cases.sample_data.jps[sample_id]\n",
    "\n",
    "Z = KDE\n",
    "#renormalize to integrate to one\\:\n",
    "mob_1d_mids = x_flat[:,0]\n",
    "jp_1d_mids = y_flat[0,:]\n",
    "integral = np.trapz(Z, jp_1d_mids, axis = 1)\n",
    "integral = np.trapz(integral, mob_1d_mids)\n",
    "Z = Z/integral\n",
    "\n",
    "mob_1d_grid=np.linspace(0.005,0.025,res)\n",
    "jp_1d_grid=np.linspace(0,0.001,res+1) # +1 makes sure the sizes are different so that axis dont get mixed up anywhere, can delete once running\n",
    "print(mob_1d_grid.shape, jp_1d_grid.shape)\n",
    "\n",
    "mob_marginal = np.trapz(Z, jp_1d_mids, axis = 1)\n",
    "jp_marginal = np.trapz(Z, mob_1d_mids, axis = 0)\n",
    "\n",
    "# --------- Calculate marginal mobility credible interval bounds ---------\n",
    "# Make CDF for marginal mobility\n",
    "CDF=np.zeros_like(mob_1d_grid)\n",
    "CDF[1:]=np.cumsum(mob_marginal/np.sum(mob_marginal)) # Leave the first term as zero\n",
    "CDF_interp=sci.interpolate.interp1d(mob_1d_grid, CDF, kind='linear') # Input is mob, output is probability\n",
    "inv_CDF_interp=sci.interpolate.interp1d(CDF, mob_1d_grid, kind='linear') # Input is value 0 to 1\n",
    "\n",
    "#Calculate marginal CIs for mobility\n",
    "upper_95_CI_mob = inv_CDF_interp(1-0.025)\n",
    "lower_95_CI_mob = inv_CDF_interp(0.025)\n",
    "upper_50_CI_mob = inv_CDF_interp(1-0.25)\n",
    "lower_50_CI_mob = inv_CDF_interp(0.25)\n",
    "\n",
    "# --------- Calculate marginal jumping prob credible interval bounds ---------\n",
    "# Make CDF for marginal jp\n",
    "CDF=np.zeros_like(jp_1d_grid)\n",
    "CDF[1:]=np.cumsum(jp_marginal/np.sum(jp_marginal)) # Leave the first term as zero\n",
    "CDF_interp=sci.interpolate.interp1d(jp_1d_grid, CDF, kind='linear') # Input is mob, output is probability\n",
    "inv_CDF_interp=sci.interpolate.interp1d(CDF, jp_1d_grid, kind='linear') # Input is value 0 to 1\n",
    "\n",
    "#Calculate marginal CIs for jp\n",
    "upper_95_CI_jp = inv_CDF_interp(1-0.025)\n",
    "lower_95_CI_jp = inv_CDF_interp(0.025)\n",
    "upper_50_CI_jp = inv_CDF_interp(1-0.25)\n",
    "lower_50_CI_jp = inv_CDF_interp(0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------Posterior plot with 95 and 50% credible intervals (WITH colorbar) ------------------\n",
    "colors = [(0.9,0,0,c) for c in np.linspace(0,1,100)]\n",
    "cmapred = mcolors.LinearSegmentedColormap.from_list('mycmap', colors, N=2)\n",
    "colors = [(0.9,0.6,0.6,c) for c in np.linspace(0,1,100)]\n",
    "cmapblue = mcolors.LinearSegmentedColormap.from_list('mycmap', colors, N=2)\n",
    "\n",
    "color_1 = (237/255,248/255,251/255)\n",
    "color_2 = (35/255,139/255,69/255)\n",
    "\n",
    "colors = [color_1, color_2]\n",
    "\n",
    "my_colormap = mcolors.LinearSegmentedColormap.from_list(\"CustomColormap\", colors)\n",
    "\n",
    "fig, ax = plt.subplots(dpi = 500, figsize = (4, 3.5))\n",
    "ax_main = plt.subplot()\n",
    "pcm = ax_main.pcolormesh(y_flat, x_flat, Z, cmap=my_colormap)\n",
    "\n",
    "plt.xlabel('Jumping probability')\n",
    "plt.ylabel('Mobility')\n",
    "plt.scatter(actual_jp, actual_mob, c='blue', label = 'True parameter', marker ='*')\n",
    "plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "plt.yticks(np.linspace(0.005, 0.025, 5))\n",
    "#     plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.legend()\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "exp_value = 5 #MANUALLY SET THE EXP VALUE FOR SCI NOTATION ON COLORBAR\n",
    "\n",
    "def fmt(x, pos):\n",
    "    return str(round(x/(10**exp_value), 2))\n",
    "\n",
    "ax_cbar = plt.subplot()\n",
    "cbar = fig.colorbar(pcm, format=ticker.FuncFormatter(fmt))\n",
    "cbar.set_label('Probability density')\n",
    "\n",
    "# # Adding exponent value at the top\n",
    "cbar.ax.text(1.05, 1, f\"1e{exp_value}\", transform=cbar.ax.transAxes, va='bottom', ha='left')\n",
    "\n",
    "#     cbar.set_ticks([])  # Remove tick labels from the colorbar\n",
    "\n",
    "# plt.savefig('figs_final/ABC_results_2D_posterior-with-colorbar-sample'+str(sample_id)+'.png',bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ----------------- Marginal plots --------------------\n",
    "print('mob marginal integral', np.trapz(mob_marginal, mob_1d_mids))\n",
    "print('jp marginal integral', np.trapz(jp_marginal, jp_1d_mids))\n",
    "\n",
    "#jumping probability marginal:\n",
    "plt.figure(figsize = (3.5, 1), dpi = 500)\n",
    "plt.plot(jp_1d_mids, jp_marginal, linewidth=2, color = color_2)\n",
    "plt.xlim(0,0.001)\n",
    "plt.axvline(actual_jp, linewidth=2, color = \"blue\", linestyle = \"--\") #true param\n",
    "plt.axvline(upper_95_CI_jp, linewidth=2, color = (0.9,0,0))\n",
    "plt.axvline(lower_95_CI_jp, linewidth=2, color = (0.9,0,0))\n",
    "plt.axvline(upper_50_CI_jp, linewidth=2, color = (0.9,0.6,0.6))\n",
    "plt.axvline(lower_50_CI_jp, linewidth=2, color = (0.9,0.6,0.6))\n",
    "plt.xticks([])\n",
    "# plt.savefig('figs_final/ABC_results_JP_marginal_posterior-sample'+str(sample_id)+'.png',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#mobility marginal:\n",
    "plt.figure(figsize = (3.5, 1), dpi = 500)\n",
    "plt.scatter([], [], c='blue', marker=\"*\", label='True parameter')\n",
    "plt.axvline(actual_mob, linewidth=2, color = \"blue\", label='True parameter', linestyle = \"--\") #true param\n",
    "plt.plot(mob_1d_mids, mob_marginal, linewidth=2, color = color_2, label = 'Marginal posterior')\n",
    "plt.xlim(0.025,0.005)\n",
    "plt.axvline(upper_95_CI_mob, linewidth=2, color = (0.9,0,0), label='Marginal 95% CI')\n",
    "plt.axvline(lower_95_CI_mob, linewidth=2, color = (0.9,0,0))\n",
    "plt.axvline(upper_50_CI_mob, linewidth=2, color = (0.9,0.6,0.6), label='Marginal 50% CI')\n",
    "plt.axvline(lower_50_CI_mob, linewidth=2, color = (0.9,0.6,0.6))\n",
    "plt.xticks(np.linspace(0.0050,0.025,9))\n",
    "plt.xticks([])\n",
    "# plt.legend(bbox_to_anchor=(1.3, 0.95))\n",
    "# plt.savefig('figs_final/ABC_results_MOB_marginal_posterior-sample'+str(sample_id)+'.png',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "631b5a63fa3f4765e1351030ef8cf691cfd4d1c32a3a03a6bedf1fe176832cce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
